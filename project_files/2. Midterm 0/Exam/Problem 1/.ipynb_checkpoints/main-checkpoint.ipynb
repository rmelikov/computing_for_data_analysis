{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 1: Ingredient substitutions\n",
    "\n",
    "_Version 1.2c_\n",
    "\n",
    "This problem is a data mining task that exercises basic data structure manipulation, Notebook 2 (pairwise association mining), and some simple linear algebra concepts (vectors, dot products).\n",
    "\n",
    "- All exercises depend on a correct Exercise 0 (1 point).\n",
    "- Exercise 1 is \"standalone\" (1 point). No subsequent exercises depend on it.\n",
    "- Exercise 2 is \"standalone\" (2 points). No subsequent exercises depend on it.\n",
    "- Exercises 3 (2 points) and 4 (2 points) are independent of each other.\n",
    "- Exercise 5 (2 points) depends on Exercises 3 and 4.\n",
    "\n",
    "> Exercise 5 can be challenging, and its test cells will only be efficient if you have reasonably efficient implementations of the pieces. When you submit to th autograder, there will be a 120 second (2 minute) time limit for your notebook. So, do keep in mind that it is only worth two (2) points and allocate your time accordingly.\n",
    "\n",
    "**Pro-tips.**\n",
    "- If your program behavior seem strange, try resetting the kernel and rerunning everything.\n",
    "- If you mess up this notebook or just want to start from scratch, save copies of all your partial responses and use `Actions` $\\rightarrow$ `Reset Assignment` to get a fresh, original copy of this notebook. (_Resetting will wipe out any answers you've written so far, so be sure to stash those somewhere safe if you intend to keep or reuse them!_)\n",
    "- If you generate excessive output (e.g., from an ill-placed `print` statement) that causes the notebook to load slowly or not at all, use `Actions` $\\rightarrow$ `Clear Notebook Output` to get a clean copy. The clean copy will retain your code but remove any generated output. **However**, it will also **rename** the notebook to `clean.xxx.ipynb`. Since the autograder expects a notebook file with the original name, you'll need to rename the clean notebook accordingly.\n",
    "\n",
    "**Good luck!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Your problem and goals ##\n",
    "\n",
    "Suppose you are cooking and following a recipe, but you discover you are missing an ingredient. You don't have time to run to the store. What would be a valid substitute? Let's implement a scheme to make automatic suggestions using basic Python and the results of Notebook 2 (pairwise association mining).\n",
    "\n",
    "### A \"high-level\" idea ###\n",
    "\n",
    "Here is an outline of a possible method. Suppose we have access to a large database of recipes. We'll start by looking for one or more recipes that are similar to ours. Then, we'll look at what ingredients they use that do **not** appear in our recipe. Among those candidate ingredients, we'll again try to find which ones are most similar to the one we are missing.\n",
    "\n",
    "To make this work, we'll need to\n",
    "\n",
    "* process the database (Exercises 0 and 1);\n",
    "* define what \"recipe-similarity\" means (Exercise 2);\n",
    "* define what \"ingredient-similarity\" means (Exercises 3 and 4);\n",
    "* and then assemble these pieces (Exercise 5).\n",
    "\n",
    "The exercises below will walk you through this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## The recipes database ##\n",
    "\n",
    "The dataset is a collection of almost 40,000 recipes. Run the code cell below to load it into a global variable named `recipes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from problem_utils import get_path\n",
    "\n",
    "with open(get_path(\"train.json\"), \"rt\") as fp:\n",
    "    recipes = json.load(fp)\n",
    "    \n",
    "print(f\"==> The dataset contains {len(recipes)} recipes.\")\n",
    "print(f\"    The variable `recipes` has type `{type(recipes)}`.\")\n",
    "\n",
    "print(f\"\\nThe first three elements are as follows:\\n\")\n",
    "for k, r in enumerate(recipes[:3]):\n",
    "    print(f\"{k}: {r}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Observe that `recipes` is a list. Each element of the list is a dictionary, which is a recipe represented by a unique integer ID, a cuisine type, and a list of its ingredients.\n",
    "\n",
    "For this problem, we will largely ignore the `'id'` and `'cuisine'` keys, so let's write a quick function to help extract just the ingredients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 0** (1 point). Let `recipe` be a single recipe from the `recipes` list. Complete the function, `get_ingredients(recipe)`, below, so that it returns the list of the ingredients in `recipe`.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "assert get_ingredients(recipes[1]) == ['plain flour', 'ground pepper', 'salt', 'tomatoes', 'ground black pepper', 'thyme', 'eggs', 'green tomatoes', 'yellow corn meal', 'milk', 'vegetable oil']\n",
    "```\n",
    "\n",
    "> The returned list should preserve the exact names and orders of ingredients as they appear in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ingredients(recipe):\n",
    "    return recipe['ingredients']\n",
    "    \n",
    "# Demo:\n",
    "get_ingredients(recipes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex0_get_ingredients",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `ex0_get_ingredients` (1 point)\n",
    "\n",
    "print(\"\"\"\n",
    "This test cell is marked as having a hidden test, but does not.\n",
    "The testing code is exposed, below, but the solution values\n",
    "are masked using hashed values.\n",
    "\"\"\")\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "\n",
    "def ex0_check__(recipes):\n",
    "    from problem_utils import check_hash\n",
    "    with open(get_path('ex0_soln.csv'), 'rt') as fp:\n",
    "        for k, r in enumerate(recipes):\n",
    "            i_your_soln = get_ingredients(r)\n",
    "            i_true_soln_hashed = fp.readline().strip()\n",
    "            assert check_hash(repr(i_your_soln), i_true_soln_hashed), \\\n",
    "                   f\"For recipe {r['id']} (`recipes[{k}]`), your result is {i_your_soln}, which does not match what we expect.\"\n",
    "            \n",
    "ex0_check__(recipes)\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Generalizing `make_itemsets()` from Notebook 2 ###\n",
    "\n",
    "Recall the `make_itemsets()` function from Notebook 2, Part 0, Exercise 3 (`nb2.0.3`). The sample solution was:\n",
    "```python\n",
    "def make_itemsets(item_lists): # nb2.0.3, sample solution\n",
    "    return [set(i) for i in item_lists]\n",
    "```\n",
    "\n",
    "Recall that from this definition, you could call this function on a list of two grocery baskets and obtain a list of itemsets as a result, e.g.,\n",
    "```python\n",
    "assert make_itemsets([['milk', 'eggs', 'bread'], ['beer', 'eggs']]) \\\n",
    "       == [{'bread', 'eggs', 'milk'}, {'beer', 'eggs'}]\n",
    "```\n",
    "But suppose we wish to make itemsets from the ingredient lists given the `recipes` object. Calling `make_itemsets(recipes)` won't work! The ingredients list requires an extra step to extract the ingredients list, by applying the function `get_ingredients()` you defined in Exercise 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your colleague suggests a common Python pattern: create a new function that can achieve this task, with the signature:\n",
    "```python\n",
    "def make_itemsets_apply(item_lists, extractor=...):\n",
    "    ...\n",
    "```\n",
    "This function accepts a second argument, named `extractor`, which can be any user-supplied **function** for getting the data from one input element to be converted into an itemset. For example, if you have an identity function,\n",
    "```python\n",
    "def identity(x):\n",
    "    return x\n",
    "```\n",
    "then ```make_itemsets_apply(X, extractor=identity)``` should behave the same as `make_itemsets(X)`. And if we implement it correctly, then we should be able to run it **directly** on the `recipes` database to get ingredient itemsets via a call like,\n",
    "```python\n",
    "ingredient_sets = make_itemsets_apply(recipes, extractor=get_ingredients)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 1** (1 point). Complete the implementation of `make_itemsets_apply()` so that it behaves as described above. If implemented correctly, then\n",
    "```python\n",
    "ingredient_sets = make_itemsets_apply(recipes, extractor=get_ingredients)\n",
    "```\n",
    "will produce a result such that\n",
    "```python\n",
    "assert ingredient_sets[0] == {'pepper', 'feta cheese crumbles', 'garbanzo beans', 'grape tomatoes', 'black olives', 'garlic', 'romaine lettuce', 'seasoning', 'purple onion'}\n",
    "assert ingredient_sets[1] == {'tomatoes', 'green tomatoes', 'ground pepper', 'eggs', 'vegetable oil', 'yellow corn meal', 'thyme', 'ground black pepper', 'plain flour', 'salt', 'milk'}\n",
    "# ... and so on ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity(x):  # a function that just returns the input\n",
    "    return x\n",
    "\n",
    "def make_itemsets_apply(item_lists, extractor=identity):\n",
    "    return [set(extractor(d)) for d in item_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demo of your function:\n",
    "def make_ingredient_sets(recipes):\n",
    "    return make_itemsets_apply(recipes, extractor=get_ingredients)\n",
    "    \n",
    "ingredient_sets = make_ingredient_sets(recipes)\n",
    "print(ingredient_sets[0])\n",
    "print(ingredient_sets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1_make_itemsets_extract",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `ex1_make_itemsets_extract` (1 point)\n",
    "\n",
    "print(\"\"\"\n",
    "This test cell is marked as having a hidden test, but does not.\n",
    "The testing code is exposed, below.\n",
    "\"\"\")\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "\n",
    "def ex1b_general_extractor__(obj, field):\n",
    "    return obj[field]\n",
    "\n",
    "def ex1b_gen_rand_keys__(max_keys):\n",
    "    from random import randrange, choices\n",
    "    num_keys = randrange(1, max_keys)\n",
    "    return set([''.join(choices('abcdefghijklmnopqrstuvwxyz', k=5)) for _ in range(num_keys)])\n",
    "\n",
    "def ex1b_gen_rand_dict_vals__(keys, key0, max_vals):\n",
    "    from random import randrange\n",
    "    D = {}\n",
    "    R = None\n",
    "    for k in keys:\n",
    "        num_vals = randrange(1, max_vals)\n",
    "        D[k] = [randrange(-100, 100) for _ in range(num_vals)]\n",
    "        if k == key0:\n",
    "            R = set(D[k])\n",
    "    assert R is not None\n",
    "    return D, R\n",
    "\n",
    "def ex1b_check_one__(max_keys, max_len, verbose=True):\n",
    "    from random import randrange, choice\n",
    "    keys = ex1b_gen_rand_keys__(max_keys)\n",
    "    key0 = choice(list(keys))\n",
    "    len_item_lists = randrange(10)\n",
    "    item_lists = []\n",
    "    R_true = []\n",
    "    for _ in range(len_item_lists):\n",
    "        D, R = ex1b_gen_rand_dict_vals__(keys, key0, max_len)\n",
    "        item_lists.append(D)\n",
    "        R_true.append(R)\n",
    "    print(f\"\"\"\n",
    "=== Test case ===\n",
    "\n",
    "* item_lists == {item_lists}\n",
    "\n",
    "* Expected result when extracting key '{key0}' == {R_true}\"\"\")\n",
    "    extractor__ = lambda x: ex1b_general_extractor__(x, key0)\n",
    "    R_you = make_itemsets_apply(item_lists, extractor=extractor__)\n",
    "    assert R_you == R_true, f\"*** Failed ***\\nYour result when extracting key '{key0}': {R_you}\"\n",
    "\n",
    "for _ in range(10): # Ten randomly generated test cases\n",
    "    ex1b_check_one__(5, 10)\n",
    "    \n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Ingredient (item)sets ###\n",
    "\n",
    "In case you weren't able to get Exercise 1 working, we've precomputed itemsets for the recipes database. Run the following code cell to load them into an object, `ingredient_sets`, which will hold these _ingredient itemsets_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def load_ingredient_sets(infilename=\"ex1a_soln.pickle\"):\n",
    "    from pickle import load\n",
    "    with open(get_path(infilename), \"rb\") as fp:\n",
    "        ingredient_sets = load(fp)\n",
    "    return ingredient_sets\n",
    "\n",
    "ingredient_sets = load_ingredient_sets()\n",
    "print(f\"Found {len(ingredient_sets)} ingredient itemsets.\")\n",
    "print(\"Examples:\")\n",
    "print(\"\\n- ingredient_sets[0]:\\n\", ingredient_sets[0])\n",
    "print(\"\\n- ingredient_sets[1]:\\n\", ingredient_sets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Recipe similarity\n",
    "\n",
    "From the preceding exercise, we now have each recipe represented by an itemset.\n",
    "\n",
    "Next, consider two recipes, $a$ and $b$. Define their _recipe-similarity_ to be the number of ingredients they have in common. For instance, consider the following two recipes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def print_ingredient_set(i, header=None):\n",
    "    if header is not None:\n",
    "        print(header)\n",
    "    for ingredient in i:\n",
    "        print(f\"- {ingredient}\")\n",
    "        \n",
    "print_ingredient_set(ingredient_sets[0], \"[0]\")\n",
    "print()\n",
    "print_ingredient_set(ingredient_sets[34089], \"[34089]\")\n",
    "print()\n",
    "common_01 = ingredient_sets[0] & ingredient_sets[34089]\n",
    "print(\"==> Common ingredients:\\n\", common_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "These two recipes share the ingredients, `'black olives'`, `'feta cheese crumbles'`, `'garbanzo beans'`, `'garlic'`,  `'purple onion'`. Therefore, the recipe-similarity score is 5.\n",
    "\n",
    "Given the itemsets, it is easy to measure similarity! The function below, `recipe_similarity(a, b)` does so, given two ingredient sets `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def recipe_similarity(a, b):\n",
    "    assert isinstance(a, set) and isinstance(b, set)\n",
    "    return len(a & b)\n",
    "\n",
    "# Demo:\n",
    "print(recipe_similarity(ingredient_sets[0], ingredient_sets[34089]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 2** (2 points). Suppose you are given the following:\n",
    "\n",
    "- A list of ingredient itemsets, named `I`;\n",
    "- An integer index `i` corresponding to one of these, `I[i]`.\n",
    "- A positive integer `k` such that `1 <= k < len(I)`.\n",
    "\n",
    "Complete the function, `get_closest_recipes(I, i, k)` so that it returns a list of the `k` _indices_ corresponding to the itemsets that are most similar to `I[i]`. That is, it should measure the recipe-similarity between `I[i]` and all other `I[j]`, where `j != i`, returning the `j` values whose itemsets are closest. You can (and should!) use the `recipe_similarity()` function that we defined for you above.\n",
    "\n",
    "For example, for `ingredient_sets[0]`, it turns out the 3 other closest itemsets are `ingredient_sets[12869]`, `ingredient_sets[34089]`, and `ingredient_sets[795]`. Therefore:\n",
    "\n",
    "```python\n",
    "assert get_closest_recipes(ingredient_sets, 0, 3) == [12869, 34089, 795]\n",
    "```\n",
    "\n",
    "> **Note 0**: Of course, `I[i]` will be a perfect match to itself! However, `i` should not be part of the returned list.\n",
    ">\n",
    "> **Note 1**: In the event of ties that result in more than `k` matches, you may return any subset. For instance, suppose `k=3` and the top similarity scores are 5, 5, 4, 4, 4, 3. In this case, your result must include the indices corresponding to the two \"5\" scores, but for the third returned value, may return any of the indices corresponding to the three \"4\" scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest_recipes(I, i, k):\n",
    "    assert i >= 0 and i < len(I)\n",
    "    assert k >= 1 and k < len(I)\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demo:\n",
    "print_ingredient_set(ingredient_sets[0], \"==> `ingredient_sets[0]`:\")\n",
    "\n",
    "top_3_closest_to_0 = get_closest_recipes(ingredient_sets, 0, 3)\n",
    "\n",
    "print(\"\\n=== Three closest recipes ===\")\n",
    "for j in top_3_closest_to_0:\n",
    "    sj = recipe_similarity(ingredient_sets[0], ingredient_sets[j])\n",
    "    print_ingredient_set(ingredient_sets[j], f\"\\n`ingredient_sets[{j}]` (similiarity={sj}):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2_get_closest_recipes",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test cell: `ex2_get_closest_recipes` (2 points)\n",
    "\n",
    "print(\"\"\"\n",
    "This test cell is marked as having a hidden test, but does not.\n",
    "The testing code is exposed, below.\n",
    "\"\"\")\n",
    "\n",
    "def ex2_check_one__():\n",
    "    from random import randrange\n",
    "    \n",
    "    def gen_random_token():\n",
    "        from random import choice\n",
    "        consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "        vowels = 'aeiou'\n",
    "        return choice(consonants) + choice(vowels) + choice(consonants)\n",
    "\n",
    "    def gen_random_soln(S, m): # Gen `m` subsets from `S`\n",
    "        from random import shuffle\n",
    "        assert isinstance(S, set)\n",
    "        assert len(S) >= m\n",
    "        T = [set() for _ in range(m)]\n",
    "        N = list(range(m))\n",
    "        shuffle(N)\n",
    "        for k, x in enumerate(S):\n",
    "            for i in range(m):\n",
    "                if i <= k:\n",
    "                    T[N[i]].add(x)\n",
    "        return T, N\n",
    "    \n",
    "    print(\"\\n=== Test case ===\\n\")\n",
    "    S = set([gen_random_token() for _ in range(10)])\n",
    "    I, N = gen_random_soln(S, randrange(2, len(S)))\n",
    "    i = N[0]\n",
    "    k = randrange(1, len(I))\n",
    "    soln = N[1:k+1]\n",
    "    \n",
    "    print(\"* I ==\")\n",
    "    for j, t in enumerate(I):\n",
    "        print(f\"  [{j}]\", t)\n",
    "    print(f\"* i == {i}\")\n",
    "    print(f\"* k == {k}\")\n",
    "    your_soln = get_closest_recipes(I, i, k)\n",
    "    assert your_soln == soln, \\\n",
    "           f\"*** Failed ***\\n\" \\\n",
    "           f\"- Expected solution: {soln}\\n\" \\\n",
    "           f\"- Your solution: {your_soln}\\n\"\n",
    "    \n",
    "for _ in range(10):\n",
    "    ex2_check_one__()\n",
    "    \n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "    \n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Closest recipes\n",
    "\n",
    "Just in case you did not get a working solution for Exercise 2, we have precomputed the five (5) closest recipes for every recipe. The following code cell will load this data in a list, `closest`. For each ingredient set `ingredient_sets[i]`, the entry `closest[i]` is a list of the indices of the 5 other closest ingredient sets in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def load_closest(infile='closest.pickle'):\n",
    "    from pickle import load\n",
    "    with open(get_path(infile), 'rb') as fp:\n",
    "        return load(fp)\n",
    "    \n",
    "print(\"Loading precomputed list of closest itemsets...\")\n",
    "closest = load_closest()\n",
    "print_ingredient_set(ingredient_sets[0], f\"\\n`ingredient_sets[0]`:\")\n",
    "print(\"\\nFive closest ingredient sets:\")\n",
    "for j in closest[0]:\n",
    "    sj = recipe_similarity(ingredient_sets[0], ingredient_sets[j])\n",
    "    print_ingredient_set(ingredient_sets[j], f\"\\n`ingredient_sets[{j}]` (similiarity={sj}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Ingredient similarity\n",
    "\n",
    "Above, you created a function to measure the similarity of recipes. What about ingredients -- how can we measure how similar two ingredients are?\n",
    "\n",
    "One \"tool\" we have from Notebook 2 is a pairwise association miner. Recall that this tool calculates the _confidence_, $\\mathrm{conf}(a \\implies b)$, which is an estimate of the conditional probability of $b$ given $a$. Run the code cell below, which runs the a modified version of the code from Notebook 2 on the ingredient itemsets, producing two results:\n",
    "\n",
    "1. The pairwise association rules among ingredients, i.e., $\\mathrm{conf}(a \\implies b)$ where $a$ and $b$ are ingredients (by name). These are stored in the `rules` object.\n",
    "2. The number of recipes in which each ingredient appears, stored in `ingredient_counts`. That is, `ingredient_counts[a]` is the number of recipes containing the ingredient named `a`.\n",
    "\n",
    "> **Note**: The `find_assoc_rules()` function, below, looks for all rules (threshold is 0.0) but excludes ingredients that appear in fewer than 25 recipes (`min_item_count=25`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from assocmine import find_assoc_rules, count_items, print_rules\n",
    "\n",
    "print(\"Counting the occurrences of each ingredient...\")\n",
    "ingredient_counts = count_items(ingredient_sets)\n",
    "print(f\"==> Found {len(ingredient_counts)} distinctly named ingredients.\")\n",
    "\n",
    "print(\"\\nNow running the association rule miner from Notebook 2...\")\n",
    "rules = find_assoc_rules(ingredient_sets, 0.0, min_item_count=25)\n",
    "print(f\"==> Found {len(rules)} rules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "> Observe that there are **many** ingredients and rules, so do be careful if you are trying to print them!\n",
    "\n",
    "Here is a quick demo of how you can use these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "a_ex = 'lemon'\n",
    "n_ex = ingredient_counts[a_ex]\n",
    "print(f\"Ingredient '{a_ex}' occurs {n_ex} times.\")\n",
    "\n",
    "b_ex = 'salt'\n",
    "c_ex = rules[(a_ex, b_ex)]\n",
    "print(f\"\\nconf('{a_ex}', '{b_ex}') = {c_ex}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(Sparse) ingredient vectors.** Given an ingredient named `a`, its _ingredient vector_ is a dictionary such that:\n",
    "\n",
    "- each key `b` is the name of another ingredient; and\n",
    "- the corresponding value is the confidence `conf(a => b)`.\n",
    "\n",
    "For example, the ingredient `'lemon'` occurs in 1,218 recipes and ends up in 1,108 rules (of the form, $\\mathtt{'lemon'} \\implies b$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cip_ex = 'lemon'\n",
    "print(f\"There are {ingredient_counts[cip_ex]} recipes containing '{cip_ex}'.\")\n",
    "\n",
    "cip_ex_rules = {(a, b): conf_ab for (a, b), conf_ab in rules.items() if a == cip_ex}\n",
    "print(f\"This ingredient appears in\", len(cip_ex_rules), \"rules.\")\n",
    "print(\"The top five by confidence are:\")\n",
    "print_rules(cip_ex_rules, rank=5, prefix=\"- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 3** (2 points). Complete the function,\n",
    "\n",
    "```python\n",
    "def ingredient_vector(a, rules):\n",
    "    ...\n",
    "```\n",
    "\n",
    "so that it returns the ingredient vector for the ingredient named `a`, using the confidence rules in `rules`. For example,\n",
    "\n",
    "```python\n",
    "assert ingredient_vector('lemon', rules) == \\\n",
    "       {'white wine': 0.027093596059113302,\n",
    "        'salmon fillets': 0.0090311986863711,\n",
    "        'pesto': 0.004105090311986864,\n",
    "        'saffron': 0.010673234811165846,       {'graham cracker crumbs': 0.1,\n",
    "        ...\n",
    "       } # 45 key-value pairs\n",
    "```\n",
    "\n",
    "If there are no rules `conf(a => b)`, then the function should return an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingredient_vector(a, rules):\n",
    "    from collections import defaultdict\n",
    "    assert isinstance(a, str)\n",
    "    assert isinstance(rules, dict) or isinstance(rules, defaultdict)\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "ingredient_vector('lemon', rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex3_ingredient_vector",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `ex3_ingredient_vector` (2 points)\n",
    "\n",
    "def ex3_gen_soln__():\n",
    "    from random import choice, sample, randrange, random\n",
    "    from itertools import permutations\n",
    "    def random_value():\n",
    "        return round(random(), 2)\n",
    "    nouns = {'tacos', 'prism', 'taxidermy', 'ennui', 'salvia', 'biodiesel', 'palo', 'dreamcatcher', 'listicle', 'shaman', 'humblebrag', 'tile', 'iphone', 'knausgaard', 'distillery', 'fanny', 'party', 'taiyaki', 'single-origin', 'santo', 'batch', 'keffiyeh', 'gluten-free', 'fingerstache', 'pop-up', 'swag', 'chicken', 'art', 'helvetica', 'pack', 'fixie', 'subway', 'semiotics', 'plaid', 'coffee', 'kogi', 'twee', 'post-ironic', 'hot', 'bulb', 'narwhal'}\n",
    "    a0 = choice(list(nouns))\n",
    "    num_elems = randrange(1, min(10, len(nouns)))\n",
    "    vec = {}\n",
    "    rules = {}\n",
    "    B = sample(list(nouns - {a0}), k=num_elems)\n",
    "    for b in B:\n",
    "        vec[b] = random_value()\n",
    "        rules[(a0, b)] = vec[b]\n",
    "    A = sample(list(nouns - {a0}), k=randrange(1, 5))\n",
    "    for a in A:\n",
    "        B = sample(list(nouns - {a} | {a0}), k=randrange(1, 5))\n",
    "        for b in B:\n",
    "            if (a, b) not in rules:\n",
    "                rules[(a, b)] = random_value()\n",
    "    return a0, vec, rules\n",
    "\n",
    "def ex3_check_one__():\n",
    "    a, vec, rules = ex3_gen_soln__()\n",
    "    print(\"\\n=== Test case ===\\n\")\n",
    "    print(f\"* a == '{a}'\\n\")\n",
    "    print(f\"* rules == {rules}\\n\")\n",
    "    print(f\"\\n* Expected result == {vec}\\n\")\n",
    "    your_vec = ingredient_vector(a, rules)\n",
    "    assert vec == your_vec, \\\n",
    "           f\"\\n*** Failed ***\\n* Your function returned {your_vec}, which is not expected.\"\n",
    "    \n",
    "for _ in range(10):\n",
    "    ex3_check_one__()\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Ingredient dot-product.** Given two ingredient vectors, `x` and `y`, the _ingredient dot-product, is the sum of `x[a] * y[a]` for all ingredients `a` that appear in both vectors.\n",
    "\n",
    "For example, suppose\n",
    "\n",
    "```python\n",
    "x = {'milk': 0.2, 'eggs': 0.7, 'bread': 0.1, 'grape tomatoes': 0.33}\n",
    "y = {'eggs': 0.3, 'lemon': 0.5, 'grape tomatoes': 0.1, 'dill': 0.8}\n",
    "```\n",
    "\n",
    "The two vectors have `'eggs'` and `'grape tomatoes'` in common. Therefore, their ingredient dot-product is $(0.7*0.3) + (0.33 * 0.1) = 0.243$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 4** (2 points). Complete the function, `ingredient_dot(x, y)`, so that it computes the similarity between two ingredient vectors, `x` and `y`, per the definition above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingredient_dot(x, y):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demo:\n",
    "x = {'milk': 0.2, 'eggs': 0.7, 'bread': 0.1, 'grape tomatoes': 0.33}\n",
    "y = {'eggs': 0.3, 'lemon': 0.5, 'grape tomatoes': 0.1, 'dill': 0.8}\n",
    "print(ingredient_dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex4_ingredient_dot",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test cell: `ex4_ingredient_dot` (2 points)\n",
    "\n",
    "def ex4_gen_soln__():\n",
    "    from random import choice, sample, randrange, random\n",
    "    from itertools import permutations\n",
    "    def random_value():\n",
    "        return round(random(), 2)\n",
    "    nouns = {'tacos', 'prism', 'taxidermy', 'ennui', 'salvia', 'biodiesel', 'palo', 'dreamcatcher', 'listicle', 'shaman', 'humblebrag', 'tile', 'iphone', 'knausgaard', 'distillery', 'fanny', 'party', 'taiyaki', 'single-origin', 'santo', 'batch', 'keffiyeh', 'gluten-free', 'fingerstache', 'pop-up', 'swag', 'chicken', 'art', 'helvetica', 'pack', 'fixie', 'subway', 'semiotics', 'plaid', 'coffee', 'kogi', 'twee', 'post-ironic', 'hot', 'bulb', 'narwhal'}\n",
    "    x = {}\n",
    "    y = {}\n",
    "    s = 0\n",
    "    num_common = randrange(0, len(nouns))\n",
    "    B_common = set(sample(list(nouns), k=num_common))\n",
    "    for b in B_common:\n",
    "        x[b] = random_value()\n",
    "        y[b] = random_value()\n",
    "        s += x[b] * y[b]\n",
    "    B_left = nouns - B_common\n",
    "    num_extra = randrange(0, len(B_left))\n",
    "    B_extra = sample(list(B_left), k=num_extra)\n",
    "    for b in B_extra:\n",
    "        if random() < 0.15:\n",
    "            x[b] = random_value()\n",
    "        elif random() < 0.15:\n",
    "            y[b] = random_value()\n",
    "    return x, y, s, B_common\n",
    "\n",
    "def ex4_check_one__():\n",
    "    x, y, s, common = ex4_gen_soln__()\n",
    "    print(\"\\n=== Test case ===\\n\")\n",
    "    print(f\"* Ingredient vector `x` == {x}\\n\")\n",
    "    print(f\"* Ingredient vector `y` == {y}\\n\")\n",
    "    print(f\"* Common keys == {common}\")\n",
    "    print(f\"* Expected result == {s}\\n\")\n",
    "    your_dot = ingredient_dot(x, y)\n",
    "    if abs(s) > 0:\n",
    "        rel_err = abs(your_dot - s) / abs(s)\n",
    "        passed = rel_err <= (len(common) * 1e-14)\n",
    "    else:\n",
    "        passed = your_dot == 0.0\n",
    "    assert passed, \\\n",
    "           f\"*** Failed ***\\nYour solution, {your_dot}, differs from the expected solution by more than what is expected from roundoff error.\"\n",
    "    \n",
    "for _ in range(10):\n",
    "    ex4_check_one__()\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Ingredient similarity.** If the function above is working, then we can use it to compute _ingredient-similarity_ using a formula called the _cosine similarity measure_, defined as follows and implementd in the code cell below.\n",
    "$$\n",
    "\\mathrm{similarity}(x, y) = \\frac{x^T y}{\\|x\\|_2 \\|y\\|_2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def ingredient_similarity(x, y):\n",
    "    from math import sqrt\n",
    "    num = ingredient_dot(x, y)\n",
    "    den = sqrt(ingredient_dot(x, x) * ingredient_dot(y, y))\n",
    "    return num / den if den > 0.0 else 0.0\n",
    "\n",
    "# With a little luck, grape tomatoes are more similar to cherry tomatoes than, say, milk:\n",
    "x = ingredient_vector('grape tomatoes', rules)\n",
    "y0 = ingredient_vector('cherry tomatoes', rules)\n",
    "s0 = ingredient_similarity(x, y0)\n",
    "y1 = ingredient_vector('milk', rules)\n",
    "s1 = ingredient_similarity(x, y1)\n",
    "print(f\"Similarity between 'grape tomatoes' and 'cherry tomatoes' is {s0}.\")\n",
    "print(f\"Similarity between 'grape tomatoes' and 'milk' is {s1}.\")\n",
    "if s0 > s1:\n",
    "    print(f\"   (Phew! -- {s0} > {s1})\")\n",
    "else:\n",
    "    print(f\"   (Hmmm... {s0} <= {s1}?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Putting it all together: Suggesting a substitute ingredient\n",
    "\n",
    "Start by reviewing the \"high-level idea\" from the beginning of this notebook. Then, complete Exercise 5, which implements it using a specific procedure that combines the various pieces from previous exercises.\n",
    "\n",
    "**Exercise 5** (2 points). Suppose you are cooking the recipe whose itemset is `ingredient_sets[i]`, but one of the ingredients, call it `a`, is missing. Here is a procedure to suggest a replacement.\n",
    "\n",
    "1. Recall that for each ingredient set `ingredient_sets[i]`, we precomputed a list of the 5 closest ingredient sets to it. These are stored in the global list named `closest`.\n",
    "2. For each `ingredient_sets[j]` that is among these 5 closest, create a set of all ingredients that are **not** already in `ingredient_sets[i]`. These are _replacement candidates_.\n",
    "3. Return a list of the `k` candidate ingredients most similar to `a`, using ingredient-similarity as the measure. This list should be sorted in descending order of similarity. Each element should be a pair (2-tuple) consisting of the ingredient name and its similarity score.\n",
    "\n",
    "For example,\n",
    "\n",
    "```python\n",
    "i = 0\n",
    "a = 'grape tomatoes'\n",
    "k = 4\n",
    "print(find_substitute(ingredient_sets, i, a, rules, k))\n",
    "```\n",
    "\n",
    "will return\n",
    "\n",
    "```python\n",
    "[('cherry tomatoes', 0.9622012981354563),\n",
    " ('red wine vinegar', 0.9153588672348227),\n",
    " ('roasted red peppers', 0.9080314448950159),\n",
    " ('pinenuts', 0.8833371085008624)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_substitute(ingredient_sets, i, a, rules, k=1):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demo 0: A specific recipe\n",
    "print_ingredient_set(ingredient_sets[0])\n",
    "find_substitute(ingredient_sets, 0, 'grape tomatoes', rules, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demo 1: Random recipe\n",
    "from random import randrange, choice\n",
    "i = randrange(0, len(ingredient_sets)) # random ingredient itemset\n",
    "print(f\"`ingredient_sets[{i}]`:\")\n",
    "print_ingredient_set(ingredient_sets[i])\n",
    "a = choice(list(ingredient_sets[i])) # random ingredient\n",
    "print(f\"\\nFinding substitute for {a}...\")\n",
    "find_substitute(ingredient_sets, i, a, rules, k=4) # find 4 closest substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex5_find_substitute",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell: `ex5_find_substitute` (2 points)\n",
    "\n",
    "print(\"\"\"\n",
    "This test cell is marked as having a hidden test, but does not.\n",
    "The testing code is exposed, below. However, it does compare\n",
    "against hashed solutions to obscure the true results.\n",
    "\"\"\")\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "\n",
    "def ex5_check(ingredient_sets, rules, num_cases=5, infile='ex5_soln.csv'):\n",
    "    from problem_utils import make_hash\n",
    "    from random import sample\n",
    "    print(f\"==> Checking {num_cases} random test cases...\")\n",
    "    with open(get_path(infile), 'rt') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for t, line in enumerate(sample(lines, k=num_cases)):\n",
    "            raw_fields = line.strip().split(',')\n",
    "            assert len(raw_fields) >= 5\n",
    "            i = int(raw_fields[0])\n",
    "            print(f\"\\n=== Test case #{t} / {num_cases}: `ingredient_sets[{i}]` ===\")\n",
    "            print_ingredient_set(ingredient_sets[i])\n",
    "            \n",
    "            a = raw_fields[1]\n",
    "            print(f\"\\nFinding top-3 substitutes for '{a}' ...\")\n",
    "            top_3_hashed = raw_fields[2:5]\n",
    "            \n",
    "            top_3 = find_substitute(ingredient_sets, i, a, rules, k=3)\n",
    "            print(\"==> Found:\", top_3)\n",
    "            for j, (b, s) in enumerate(top_3):\n",
    "                b_hashed = make_hash(b)\n",
    "                assert b_hashed == top_3_hashed[j], \\\n",
    "                       f\"*** Mismatch: Your #{j} item, '{b}' ({b_hashed}),\" \\\n",
    "                       f\" does not match our expected value ({top_3_hashed[j]}).\"\n",
    "                \n",
    "ex5_check(ingredient_sets, rules)\n",
    "    \n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**So how did we do?** It's not a perfect algorithm by any stretch of the imagination. There are several tuning parameters, which you'd need to play with, and we've ignored an important component of the data (namely, the cuisine type). But we hope you'll agree that, if you made it this far, it's not bad for just a few weeks into a data analysis course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin!** You’ve reached the end of this part. Don’t forget to restart and run all cells again to make sure it’s all working when run in sequence; and make sure your work passes the submission process. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
